{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "#bayesian-optimization\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Measure Performance\n",
    "from  sklearn  import  metrics\n",
    "def measure_performance(X,y,clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True, show_roc_auc = True):\n",
    "    y_pred = clf.predict(X)\n",
    "    y_predprob = clf.predict_proba(X)[:,1]\n",
    "    if show_accuracy:\n",
    "        print (\"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y,y_pred))),\"\\n\"\n",
    "\n",
    "    if show_classification_report:\n",
    "        print(\"Classification report\")\n",
    "        print(metrics.classification_report(y,y_pred)),\"\\n\"\n",
    "        \n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion matrix\")\n",
    "        print(metrics.confusion_matrix(y,y_pred)),\"\\n\"  \n",
    "        \n",
    "    if show_roc_auc:\n",
    "        print(\"ROC AUC Score\")\n",
    "        print(metrics.roc_auc_score(y,y_predprob)),\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preparation for LightGBM\n",
    "import os\n",
    "application_train = pd.read_csv('/Users/francislin/Desktop/Machine_Learning_Workshop/Home Credit Default Risk/application_train.csv')\n",
    "\n",
    "# use LabelEncoder to convert categorical features to int type before construct Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def label_encoder(input_df, encoder_dict=None):\n",
    "    \"\"\" Process a dataframe into a form useable by LightGBM \"\"\"\n",
    "    # Label encode categoricals\n",
    "    categorical_feats = input_df.columns[input_df.dtypes == 'object']\n",
    "    for feat in categorical_feats:\n",
    "        encoder = LabelEncoder()\n",
    "        input_df[feat] = encoder.fit_transform(input_df[feat].fillna('NULL'))\n",
    "    return input_df, categorical_feats.tolist(), encoder_dict\n",
    "application_train, categorical_feats, encoder_dict = label_encoder(application_train)\n",
    "X = application_train.drop('TARGET', axis=1)\n",
    "y = application_train.TARGET\n",
    "\n",
    "# Prepare dataset \n",
    "seed = 7\n",
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bayesian-optimization\n",
    "def lgb_eval(num_leaves, feature_fraction, bagging_fraction, max_depth, lambda_l1, lambda_l2, min_split_gain, min_child_weight):\n",
    "    params = {'application':'binary','num_iterations':4000, 'learning_rate':0.05, 'early_stopping_round':100, 'metric':'auc'}\n",
    "    params[\"num_leaves\"] = int(round(num_leaves))\n",
    "    params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "    params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "    params['max_depth'] = round(max_depth)\n",
    "    params['lambda_l1'] = max(lambda_l1, 0)\n",
    "    params['lambda_l2'] = max(lambda_l2, 0)\n",
    "    params['min_split_gain'] = min_split_gain\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
    "    return max(cv_result['auc-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Set the range for each parameter (make the range as narrow as possible)\n",
    "lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (24, 45),\n",
    "                                        'feature_fraction': (0.1, 0.9),\n",
    "                                        'bagging_fraction': (0.8, 1),\n",
    "                                        'max_depth': (5, 8.99),\n",
    "                                        'lambda_l1': (0, 5),\n",
    "                                        'lambda_l2': (0, 3),\n",
    "                                        'min_split_gain': (0.001, 0.1),\n",
    "                                        'min_child_weight': (5, 50)}, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Put all together\n",
    "def bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=5, random_seed=6, n_estimators=10000, learning_rate=0.05, output_process=False):\n",
    "    # prepare data\n",
    "    train_data = lgb.Dataset(data=X, label=y, categorical_feature = categorical_feats, free_raw_data=False)\n",
    "    # parameters\n",
    "    def lgb_eval(num_leaves, feature_fraction, bagging_fraction, max_depth, lambda_l1, lambda_l2, min_split_gain, min_child_weight, max_bin):\n",
    "        params = {'application':'binary','num_iterations': n_estimators, 'learning_rate':learning_rate, 'early_stopping_round':100, 'metric':'auc'}\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['lambda_l1'] = max(lambda_l1, 0)\n",
    "        params['lambda_l2'] = max(lambda_l2, 0)\n",
    "        params['min_split_gain'] = min_split_gain\n",
    "        params['min_child_weight'] = min_child_weight\n",
    "        params['max_bin'] = int(round(max_bin))\n",
    "        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
    "        return max(cv_result['auc-mean'])\n",
    "    # range \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (24, 45),\n",
    "                                            'feature_fraction': (0.1, 0.9),\n",
    "                                            'bagging_fraction': (0.8, 1),\n",
    "                                            'max_depth': (5, 8.99),\n",
    "                                            'lambda_l1': (0, 5),\n",
    "                                            'lambda_l2': (0, 3),\n",
    "                                            'min_split_gain': (0.001, 0.1),\n",
    "                                            'min_child_weight': (5, 50),\n",
    "                                           'max_bin': (5, 50)}, random_state=0)\n",
    "    # optimize\n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "    \n",
    "    # output optimization process\n",
    "    if output_process==True: lgbBO.points_to_csv(\"bayes_opt_result.csv\")\n",
    "    \n",
    "    # return best parameters\n",
    "    return lgbBO.res['max']['max_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = bayes_parameter_opt_lgb(X, y, init_round=5, opt_round=10, n_folds=3, random_seed=6, n_estimators=100, learning_rate=0.05)\n",
    "print(opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
